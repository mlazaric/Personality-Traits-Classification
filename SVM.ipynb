{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-nfUg6aSr8B"
      },
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDZ897yoTzu6"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "dataset = pd.read_csv('datasets/essays.csv', encoding='latin-1')\n",
        "\n",
        "transformation = { 'n': 0, 'y': 1 }\n",
        "\n",
        "dataset = dataset.replace({'cEXT': transformation, 'cNEU': transformation, 'cAGR': transformation, 'cCON': transformation, 'cOPN': transformation})\n",
        "\n",
        "traits = ['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77vsknwE4mFE",
        "outputId": "122836c6-881a-43ed-9696-1bb040361a52"
      },
      "source": [
        "dataset[(dataset['cOPN']==1) & (dataset['cAGR']==1)].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "#AUTHID    686\n",
              "TEXT       686\n",
              "cEXT       686\n",
              "cNEU       686\n",
              "cAGR       686\n",
              "cCON       686\n",
              "cOPN       686\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "6A-VPailr0C-",
        "outputId": "74e1cb7b-6995-4e4c-abfc-66ff0f6e074f"
      },
      "source": [
        "print(f'Number of essays {len(dataset)}')\n",
        "\n",
        "per_label_split = []\n",
        "\n",
        "for trait in traits:\n",
        "  negative_sum = sum(dataset[trait] == 0)\n",
        "  positive_sum = sum(dataset[trait] == 1)\n",
        "  total_number = len(dataset)\n",
        "\n",
        "  per_label_split.append([trait, f'{negative_sum} ({100 * negative_sum / total_number:.2f}%)', f'{positive_sum} ({100 * positive_sum / total_number:.2f}%)'])\n",
        "\n",
        "display(pd.DataFrame(per_label_split, columns=['Trait', 'Negative examples', 'Positive examples']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of essays 2467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Trait</th>\n",
              "      <th>Negative examples</th>\n",
              "      <th>Positive examples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cEXT</td>\n",
              "      <td>1191 (48.28%)</td>\n",
              "      <td>1276 (51.72%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cNEU</td>\n",
              "      <td>1234 (50.02%)</td>\n",
              "      <td>1233 (49.98%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cAGR</td>\n",
              "      <td>1157 (46.90%)</td>\n",
              "      <td>1310 (53.10%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cCON</td>\n",
              "      <td>1214 (49.21%)</td>\n",
              "      <td>1253 (50.79%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cOPN</td>\n",
              "      <td>1196 (48.48%)</td>\n",
              "      <td>1271 (51.52%)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Trait Negative examples Positive examples\n",
              "0  cEXT     1191 (48.28%)     1276 (51.72%)\n",
              "1  cNEU     1234 (50.02%)     1233 (49.98%)\n",
              "2  cAGR     1157 (46.90%)     1310 (53.10%)\n",
              "3  cCON     1214 (49.21%)     1253 (50.79%)\n",
              "4  cOPN     1196 (48.48%)     1271 (51.52%)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvVvQZ1ybOEI"
      },
      "source": [
        "docs = [nlp(text) for text in dataset['TEXT']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BklRwT08Swzo"
      },
      "source": [
        "def extract_pos_tags_counts(doc, simple_tags=True):\n",
        "  return Counter(token.pos_ if simple_tags else token.tag_ for token in doc)\n",
        "\n",
        "def extract_named_entity_counts(doc):\n",
        "  return Counter(entity.label_ for entity in doc.ents)\n",
        "\n",
        "def extract_lemma_counts(doc):\n",
        "  return Counter(token.lemma_ for token in doc)\n",
        "\n",
        "def normalize_by_sum(features):\n",
        "  total_sum = sum(features.values())\n",
        "\n",
        "  return {key: value / total_sum for key, value in features.items()}\n",
        "\n",
        "def normalize_by_constant(features, constant):\n",
        "  return {key: value / constant for key, value in features.items()}\n",
        "\n",
        "def prefix_keys(dictionary, prefix):\n",
        "  return {f'{prefix}{key}': value for key, value in dictionary.items()}\n",
        "\n",
        "def find_mean_counts():\n",
        "  for t in traits:\n",
        "    d_temp = dataset.loc[dataset[t] == 1]\n",
        "    docs = [nlp(text) for text in d_temp['TEXT']]\n",
        "\n",
        "    pos = [extract_named_entity_counts(d) for d in docs]\n",
        "    cnt = Counter([])\n",
        "    for c in pos:\n",
        "      cnt = cnt + c\n",
        "    cnt = dict(cnt)\n",
        "    for k in cnt:\n",
        "      cnt[k] = cnt[k] / len(dataset)\n",
        "    print(t)\n",
        "    print(cnt)\n",
        "\n",
        "def t_test(pos_type):\n",
        "  distributions = []\n",
        "  for t in traits:\n",
        "    d_temp = dataset.loc[dataset[t] == 1]\n",
        "    docs = [nlp(text) for text in d_temp['TEXT']]\n",
        "\n",
        "    pos = [extract_pos_tags_counts(d) for d in docs]\n",
        "    dist = [p[pos_type] for p in pos]\n",
        "    distributions.append(dist)\n",
        "\n",
        "  print(pos_type)\n",
        "  for i in range(len(distributions)):\n",
        "    for j in range(i+1, len(distributions)):\n",
        "      min_len = min(len(distributions[i]), len(distributions[j]))\n",
        "      v1 = distributions[i][:min_len]\n",
        "      v2 = distributions[j][:min_len]\n",
        "      res = ttest_ind(v1, v2, equal_var=False)\n",
        "      print(f'{traits[i]} vs {traits[j]}')\n",
        "      print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTlOdMYPS1t3"
      },
      "source": [
        "def evaluate_features_and_model(features, model_generator):\n",
        "  information = []\n",
        "\n",
        "  for trait in traits:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, dataset[trait], test_size=0.25, random_state=42, stratify=dataset[trait])\n",
        "\n",
        "    model = model_generator()\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, pred)\n",
        "    prf = precision_recall_fscore_support(y_test, pred, average='binary')\n",
        "    information.append([trait, acc, *prf])\n",
        "\n",
        "  score = pd.DataFrame(information, columns=['trait', 'accuracy', 'precision', 'recall', 'fscore', 'support'])\n",
        "\n",
        "  return score['accuracy'].tolist() + score['fscore'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TbnYrmzdF1w"
      },
      "source": [
        "model_generator = lambda: make_pipeline(DictVectorizer(sparse=False), SelectKBest(k=10), StandardScaler(), SVC(gamma='auto'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbQCCkJAei1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "5d2e6ef6-18b6-40ee-dcba-39a6161609ce"
      },
      "source": [
        "features = {\n",
        "    'Bag of words': [dict(extract_lemma_counts(doc)) for doc in docs],\n",
        "    'PoS tag counts (simple, non-normalized)': [dict(extract_pos_tags_counts(doc)) for doc in docs],\n",
        "    'PoS tag counts (detailed, non-normalized)': [dict(extract_pos_tags_counts(doc, False)) for doc in docs],\n",
        "    'Named entity type counts (non-normalized)': [dict(extract_named_entity_counts(doc)) for doc in docs],\n",
        "    'PoS + NE type counts (simple, non-normalized)': [{ **dict(extract_pos_tags_counts(doc)), **dict(extract_named_entity_counts(doc)) } for doc in docs],\n",
        "    'PoS + NE type counts (detailed, non-normalized)': [{ **dict(extract_pos_tags_counts(doc, False)), **dict(extract_named_entity_counts(doc)) } for doc in docs],\n",
        "    'PoS (basic, normalized by sum)': [normalize_by_sum(dict(extract_pos_tags_counts(doc))) for doc in docs],\n",
        "    'PoS (detailed, normalized by sum)': [normalize_by_sum(dict(extract_pos_tags_counts(doc, False))) for doc in docs],\n",
        "    'NE (normalized by sum)': [normalize_by_sum(dict(extract_named_entity_counts(doc))) for doc in docs],\n",
        "    'PoS + NE (basic, normalized by sum)': [{ **normalize_by_sum(dict(extract_pos_tags_counts(doc))), **normalize_by_sum(dict(extract_named_entity_counts(doc))) } for doc in docs],\n",
        "    'PoS + NE (detailed, normalized by sum)': [{ **normalize_by_sum(dict(extract_pos_tags_counts(doc, False))), **normalize_by_sum(dict(extract_named_entity_counts(doc))) } for doc in docs],\n",
        "    'PoS (basic, normalized by sentence count)': [normalize_by_constant(dict(extract_pos_tags_counts(doc)), len(list(doc.sents))) for doc in docs],\n",
        "    'PoS (detailed, normalized by sentence count)': [normalize_by_constant(dict(extract_pos_tags_counts(doc, False)), len(list(doc.sents))) for doc in docs],\n",
        "    'NE (normalized by sentence count)': [normalize_by_constant(dict(extract_named_entity_counts(doc)), len(list(doc.sents))) for doc in docs],\n",
        "    'PoS + NE (basic, normalized by sentence count)': [{ **normalize_by_constant(dict(extract_pos_tags_counts(doc)), len(list(doc.sents))), **normalize_by_constant(dict(extract_named_entity_counts(doc)), len(list(doc.sents))) } for doc in docs],\n",
        "    'PoS + NE (detailed, normalized by sentence count)': [{ **normalize_by_constant(dict(extract_pos_tags_counts(doc, False)), len(list(doc.sents))), **normalize_by_constant(dict(extract_named_entity_counts(doc)), len(list(doc.sents))) } for doc in docs]\n",
        "}\n",
        "results = []\n",
        "\n",
        "results.append([\"Always true baseline\", *evaluate_features_and_model([doc.vector for doc in docs], lambda: DummyClassifier(strategy='constant', constant=1))])\n",
        "results.append([\"Document vector\", *evaluate_features_and_model([doc.vector for doc in docs], lambda: make_pipeline(StandardScaler(), SVC(gamma='auto')))])\n",
        "\n",
        "for name, feature in features.items():\n",
        "  results.append([name, *evaluate_features_and_model(feature, model_generator)])\n",
        "\n",
        "score = pd.DataFrame(results, columns=['feature', *[f'{t}-{m}' for m in ['acc', 'f1'] for t in traits]])\n",
        "\n",
        "print('# Accuracy and F1 scores for different features')\n",
        "display(score)\n",
        "\n",
        "best_features = []\n",
        "\n",
        "for trait in traits:\n",
        "  max_index = max(range(len(score)), key=lambda index: score[f'{trait}-acc'][index])\n",
        "\n",
        "  best_features.append([trait, score['feature'][max_index], score[f'{trait}-f1'][max_index], score[f'{trait}-acc'][max_index]])\n",
        "\n",
        "best_features_frame = pd.DataFrame(best_features, columns=['trait', 'feature', 'f1', 'acc'])\n",
        "\n",
        "print('# Features with greatest accuracy for each trait')\n",
        "display(best_features_frame)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Accuracy and F1 scores for different features\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>cEXT-acc</th>\n",
              "      <th>cNEU-acc</th>\n",
              "      <th>cAGR-acc</th>\n",
              "      <th>cCON-acc</th>\n",
              "      <th>cOPN-acc</th>\n",
              "      <th>cEXT-f1</th>\n",
              "      <th>cNEU-f1</th>\n",
              "      <th>cAGR-f1</th>\n",
              "      <th>cCON-f1</th>\n",
              "      <th>cOPN-f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Always true baseline</td>\n",
              "      <td>0.517018</td>\n",
              "      <td>0.499190</td>\n",
              "      <td>0.531605</td>\n",
              "      <td>0.507293</td>\n",
              "      <td>0.515397</td>\n",
              "      <td>0.681624</td>\n",
              "      <td>0.665946</td>\n",
              "      <td>0.694180</td>\n",
              "      <td>0.673118</td>\n",
              "      <td>0.680214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Document vector</td>\n",
              "      <td>0.534846</td>\n",
              "      <td>0.520259</td>\n",
              "      <td>0.512156</td>\n",
              "      <td>0.546191</td>\n",
              "      <td>0.615883</td>\n",
              "      <td>0.565809</td>\n",
              "      <td>0.514754</td>\n",
              "      <td>0.582524</td>\n",
              "      <td>0.574468</td>\n",
              "      <td>0.638168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>0.536467</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.507293</td>\n",
              "      <td>0.589951</td>\n",
              "      <td>0.594814</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.455939</td>\n",
              "      <td>0.598945</td>\n",
              "      <td>0.570458</td>\n",
              "      <td>0.645892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PoS tag counts (simple, non-normalized)</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.513776</td>\n",
              "      <td>0.523501</td>\n",
              "      <td>0.515397</td>\n",
              "      <td>0.567261</td>\n",
              "      <td>0.625330</td>\n",
              "      <td>0.462366</td>\n",
              "      <td>0.641463</td>\n",
              "      <td>0.558346</td>\n",
              "      <td>0.575517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PoS tag counts (detailed, non-normalized)</td>\n",
              "      <td>0.538088</td>\n",
              "      <td>0.529984</td>\n",
              "      <td>0.515397</td>\n",
              "      <td>0.507293</td>\n",
              "      <td>0.554295</td>\n",
              "      <td>0.614344</td>\n",
              "      <td>0.474638</td>\n",
              "      <td>0.639324</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.518389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Named entity type counts (non-normalized)</td>\n",
              "      <td>0.538088</td>\n",
              "      <td>0.502431</td>\n",
              "      <td>0.505673</td>\n",
              "      <td>0.528363</td>\n",
              "      <td>0.549433</td>\n",
              "      <td>0.624506</td>\n",
              "      <td>0.518053</td>\n",
              "      <td>0.644107</td>\n",
              "      <td>0.541732</td>\n",
              "      <td>0.618132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PoS + NE type counts (simple, non-normalized)</td>\n",
              "      <td>0.555916</td>\n",
              "      <td>0.495948</td>\n",
              "      <td>0.491086</td>\n",
              "      <td>0.531605</td>\n",
              "      <td>0.606159</td>\n",
              "      <td>0.642298</td>\n",
              "      <td>0.461005</td>\n",
              "      <td>0.619855</td>\n",
              "      <td>0.544882</td>\n",
              "      <td>0.644217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PoS + NE type counts (detailed, non-normalized)</td>\n",
              "      <td>0.521880</td>\n",
              "      <td>0.529984</td>\n",
              "      <td>0.523501</td>\n",
              "      <td>0.567261</td>\n",
              "      <td>0.570502</td>\n",
              "      <td>0.608234</td>\n",
              "      <td>0.474638</td>\n",
              "      <td>0.633416</td>\n",
              "      <td>0.588598</td>\n",
              "      <td>0.557596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PoS (basic, normalized by sum)</td>\n",
              "      <td>0.546191</td>\n",
              "      <td>0.497569</td>\n",
              "      <td>0.529984</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.567261</td>\n",
              "      <td>0.593023</td>\n",
              "      <td>0.498382</td>\n",
              "      <td>0.643735</td>\n",
              "      <td>0.606648</td>\n",
              "      <td>0.611354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PoS (detailed, normalized by sum)</td>\n",
              "      <td>0.551053</td>\n",
              "      <td>0.523501</td>\n",
              "      <td>0.512156</td>\n",
              "      <td>0.487844</td>\n",
              "      <td>0.560778</td>\n",
              "      <td>0.632138</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.576653</td>\n",
              "      <td>0.540698</td>\n",
              "      <td>0.557912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NE (normalized by sum)</td>\n",
              "      <td>0.536467</td>\n",
              "      <td>0.512156</td>\n",
              "      <td>0.505673</td>\n",
              "      <td>0.560778</td>\n",
              "      <td>0.547812</td>\n",
              "      <td>0.632391</td>\n",
              "      <td>0.518400</td>\n",
              "      <td>0.610473</td>\n",
              "      <td>0.573228</td>\n",
              "      <td>0.610879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PoS + NE (basic, normalized by sum)</td>\n",
              "      <td>0.565640</td>\n",
              "      <td>0.507293</td>\n",
              "      <td>0.500810</td>\n",
              "      <td>0.552674</td>\n",
              "      <td>0.560778</td>\n",
              "      <td>0.633880</td>\n",
              "      <td>0.464789</td>\n",
              "      <td>0.614035</td>\n",
              "      <td>0.576687</td>\n",
              "      <td>0.597325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PoS + NE (detailed, normalized by sum)</td>\n",
              "      <td>0.570502</td>\n",
              "      <td>0.534846</td>\n",
              "      <td>0.500810</td>\n",
              "      <td>0.549433</td>\n",
              "      <td>0.576985</td>\n",
              "      <td>0.635488</td>\n",
              "      <td>0.528736</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.593567</td>\n",
              "      <td>0.591549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PoS (basic, normalized by sentence count)</td>\n",
              "      <td>0.555916</td>\n",
              "      <td>0.525122</td>\n",
              "      <td>0.504052</td>\n",
              "      <td>0.497569</td>\n",
              "      <td>0.565640</td>\n",
              "      <td>0.610795</td>\n",
              "      <td>0.551302</td>\n",
              "      <td>0.633971</td>\n",
              "      <td>0.535928</td>\n",
              "      <td>0.623596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PoS (detailed, normalized by sentence count)</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.531605</td>\n",
              "      <td>0.505673</td>\n",
              "      <td>0.534846</td>\n",
              "      <td>0.536467</td>\n",
              "      <td>0.553459</td>\n",
              "      <td>0.553323</td>\n",
              "      <td>0.607465</td>\n",
              "      <td>0.553655</td>\n",
              "      <td>0.551724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NE (normalized by sentence count)</td>\n",
              "      <td>0.557536</td>\n",
              "      <td>0.502431</td>\n",
              "      <td>0.504052</td>\n",
              "      <td>0.549433</td>\n",
              "      <td>0.554295</td>\n",
              "      <td>0.618182</td>\n",
              "      <td>0.532725</td>\n",
              "      <td>0.616541</td>\n",
              "      <td>0.551613</td>\n",
              "      <td>0.625850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>PoS + NE (basic, normalized by sentence count)</td>\n",
              "      <td>0.568882</td>\n",
              "      <td>0.504052</td>\n",
              "      <td>0.513776</td>\n",
              "      <td>0.551053</td>\n",
              "      <td>0.593193</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.533537</td>\n",
              "      <td>0.619289</td>\n",
              "      <td>0.585949</td>\n",
              "      <td>0.649930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PoS + NE (detailed, normalized by sentence count)</td>\n",
              "      <td>0.541329</td>\n",
              "      <td>0.536467</td>\n",
              "      <td>0.510535</td>\n",
              "      <td>0.560778</td>\n",
              "      <td>0.581848</td>\n",
              "      <td>0.573152</td>\n",
              "      <td>0.569277</td>\n",
              "      <td>0.600529</td>\n",
              "      <td>0.577223</td>\n",
              "      <td>0.616071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              feature  ...   cOPN-f1\n",
              "0                                Always true baseline  ...  0.680214\n",
              "1                                     Document vector  ...  0.638168\n",
              "2                                        Bag of words  ...  0.645892\n",
              "3             PoS tag counts (simple, non-normalized)  ...  0.575517\n",
              "4           PoS tag counts (detailed, non-normalized)  ...  0.518389\n",
              "5           Named entity type counts (non-normalized)  ...  0.618132\n",
              "6       PoS + NE type counts (simple, non-normalized)  ...  0.644217\n",
              "7     PoS + NE type counts (detailed, non-normalized)  ...  0.557596\n",
              "8                      PoS (basic, normalized by sum)  ...  0.611354\n",
              "9                   PoS (detailed, normalized by sum)  ...  0.557912\n",
              "10                             NE (normalized by sum)  ...  0.610879\n",
              "11                PoS + NE (basic, normalized by sum)  ...  0.597325\n",
              "12             PoS + NE (detailed, normalized by sum)  ...  0.591549\n",
              "13          PoS (basic, normalized by sentence count)  ...  0.623596\n",
              "14       PoS (detailed, normalized by sentence count)  ...  0.551724\n",
              "15                  NE (normalized by sentence count)  ...  0.625850\n",
              "16     PoS + NE (basic, normalized by sentence count)  ...  0.649930\n",
              "17  PoS + NE (detailed, normalized by sentence count)  ...  0.616071\n",
              "\n",
              "[18 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "# Features with greatest accuracy for each trait\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trait</th>\n",
              "      <th>feature</th>\n",
              "      <th>f1</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cEXT</td>\n",
              "      <td>PoS + NE (detailed, normalized by sum)</td>\n",
              "      <td>0.635488</td>\n",
              "      <td>0.570502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cNEU</td>\n",
              "      <td>Bag of words</td>\n",
              "      <td>0.455939</td>\n",
              "      <td>0.539708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cAGR</td>\n",
              "      <td>Always true baseline</td>\n",
              "      <td>0.694180</td>\n",
              "      <td>0.531605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cCON</td>\n",
              "      <td>Bag of words</td>\n",
              "      <td>0.570458</td>\n",
              "      <td>0.589951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cOPN</td>\n",
              "      <td>Document vector</td>\n",
              "      <td>0.638168</td>\n",
              "      <td>0.615883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  trait                                 feature        f1       acc\n",
              "0  cEXT  PoS + NE (detailed, normalized by sum)  0.635488  0.570502\n",
              "1  cNEU                            Bag of words  0.455939  0.539708\n",
              "2  cAGR                    Always true baseline  0.694180  0.531605\n",
              "3  cCON                            Bag of words  0.570458  0.589951\n",
              "4  cOPN                         Document vector  0.638168  0.615883"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "BHv2wS4NbXiw",
        "outputId": "acdc7b35-d7f5-4b6a-ecd9-1b790f48f605"
      },
      "source": [
        "best_features_frame.to_latex()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\\\begin{tabular}{lllrr}\\n\\\\toprule\\n{} & trait &                                 feature &        f1 &       acc \\\\\\\\\\n\\\\midrule\\n0 &  cEXT &  PoS + NE (detailed, normalized by sum) &  0.635488 &  0.570502 \\\\\\\\\\n1 &  cNEU &                            Bag of words &  0.455939 &  0.539708 \\\\\\\\\\n2 &  cAGR &                    Always true baseline &  0.694180 &  0.531605 \\\\\\\\\\n3 &  cCON &                            Bag of words &  0.570458 &  0.589951 \\\\\\\\\\n4 &  cOPN &                         Document vector &  0.638168 &  0.615883 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o5yDNuCsJZO0",
        "outputId": "f87f5e2a-9793-4007-e0df-7929b90f19ff"
      },
      "source": [
        "def grid_search_model_generator():\n",
        "  pipeline = make_pipeline(DictVectorizer(sparse=False), SelectKBest(), StandardScaler(), SVC())\n",
        "\n",
        "  param_grid = {\n",
        "    'selectkbest__k': [5, 10],\n",
        "    'svc__C': np.logspace(-1, 1, 3),\n",
        "    'svc__kernel': ['linear', 'poly', 'rbf'],\n",
        "    'svc__gamma': ['auto', 'scale']\n",
        "  }\n",
        "\n",
        "  search = GridSearchCV(pipeline, param_grid, n_jobs=-1, verbose=3)\n",
        "\n",
        "  return search\n",
        "\n",
        "feature = [{\n",
        "           **dict(extract_lemma_counts(doc)),\n",
        "           **prefix_keys({ **dict(extract_pos_tags_counts(doc, False)), **dict(extract_named_entity_counts(doc)) }, 'unnormalized_'),\n",
        "           **prefix_keys({ **normalize_by_sum(dict(extract_pos_tags_counts(doc, False))), **normalize_by_sum(dict(extract_named_entity_counts(doc))) }, 'percentage_'),\n",
        "           **prefix_keys({ **normalize_by_constant(dict(extract_pos_tags_counts(doc, False)), len(list(doc.sents))), **normalize_by_constant(dict(extract_named_entity_counts(doc)), len(list(doc.sents))) }, 'mean_per_sentence_') } for doc in docs]\n",
        "\n",
        "new_features = []\n",
        "for trait in traits:\n",
        "  dict2vec = DictVectorizer().fit(feature, dataset[trait])\n",
        "  kbest = SelectKBest().fit(dict2vec.transform(feature), dataset[trait])\n",
        "  \n",
        "  names = dict2vec.feature_names_\n",
        "  scores = kbest.scores_\n",
        "  pvalues = kbest.pvalues_\n",
        "\n",
        "  new_features.append([{k: f[k] for k in names[:20] if k in f} for f in feature])\n",
        "\n",
        "  print(trait)\n",
        "  display(pd.DataFrame({\n",
        "      'name': names,\n",
        "      'score': scores,\n",
        "      'pvalue': pvalues\n",
        "  }).sort_values(by=['score', 'pvalue'], ascending=[False, True]).head(20))\n",
        "\n",
        "results = []\n",
        "for i, feature in enumerate(new_features):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(feature, dataset[traits[i]], test_size=0.25, random_state=42, stratify=dataset[traits[i]])\n",
        "\n",
        "  model = model_generator()\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  pred = model.predict(X_test)\n",
        "  acc = accuracy_score(y_test, pred)\n",
        "  prf = precision_recall_fscore_support(y_test, pred, average='binary')\n",
        "  results.append([traits[i], acc, prf[2]])\n",
        "\n",
        "score = pd.DataFrame(results, columns=['feature', 'acc', 'f1'])\n",
        "\n",
        "print('# Accuracy and F1 scores for best features')\n",
        "display(score)\n",
        "\n",
        "#display(evaluate_features_and_model(\n",
        "#    feature, \n",
        "#    grid_search_model_generator\n",
        "#))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cEXT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>pvalue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26086</th>\n",
              "      <td>sorority</td>\n",
              "      <td>23.190310</td>\n",
              "      <td>0.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15512</th>\n",
              "      <td>fun</td>\n",
              "      <td>19.663663</td>\n",
              "      <td>0.000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22361</th>\n",
              "      <td>perhaps</td>\n",
              "      <td>19.204119</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10017</th>\n",
              "      <td>boyfriend</td>\n",
              "      <td>16.167508</td>\n",
              "      <td>0.000060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19862</th>\n",
              "      <td>mean_per_sentence_PRP</td>\n",
              "      <td>15.927449</td>\n",
              "      <td>0.000068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19877</th>\n",
              "      <td>mean_per_sentence_VBP</td>\n",
              "      <td>13.982336</td>\n",
              "      <td>0.000189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25857</th>\n",
              "      <td>so</td>\n",
              "      <td>13.937567</td>\n",
              "      <td>0.000193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22276</th>\n",
              "      <td>percentage_.</td>\n",
              "      <td>12.484425</td>\n",
              "      <td>0.000418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8205</th>\n",
              "      <td>all</td>\n",
              "      <td>12.408623</td>\n",
              "      <td>0.000435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15678</th>\n",
              "      <td>generally</td>\n",
              "      <td>12.312552</td>\n",
              "      <td>0.000458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12907</th>\n",
              "      <td>differ</td>\n",
              "      <td>11.297795</td>\n",
              "      <td>0.000788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19164</th>\n",
              "      <td>listen</td>\n",
              "      <td>11.160429</td>\n",
              "      <td>0.000848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19824</th>\n",
              "      <td>mean_per_sentence_.</td>\n",
              "      <td>10.903873</td>\n",
              "      <td>0.000973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23272</th>\n",
              "      <td>program</td>\n",
              "      <td>10.807250</td>\n",
              "      <td>0.001025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30213</th>\n",
              "      <td>write</td>\n",
              "      <td>10.618366</td>\n",
              "      <td>0.001135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23770</th>\n",
              "      <td>ready</td>\n",
              "      <td>10.469372</td>\n",
              "      <td>0.001230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27994</th>\n",
              "      <td>together</td>\n",
              "      <td>10.387944</td>\n",
              "      <td>0.001285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22314</th>\n",
              "      <td>percentage_PRP</td>\n",
              "      <td>10.384496</td>\n",
              "      <td>0.001287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19829</th>\n",
              "      <td>mean_per_sentence_CC</td>\n",
              "      <td>10.258421</td>\n",
              "      <td>0.001378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7813</th>\n",
              "      <td>acquaintance</td>\n",
              "      <td>10.180225</td>\n",
              "      <td>0.001437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        name      score    pvalue\n",
              "26086               sorority  23.190310  0.000002\n",
              "15512                    fun  19.663663  0.000010\n",
              "22361                perhaps  19.204119  0.000012\n",
              "10017              boyfriend  16.167508  0.000060\n",
              "19862  mean_per_sentence_PRP  15.927449  0.000068\n",
              "19877  mean_per_sentence_VBP  13.982336  0.000189\n",
              "25857                     so  13.937567  0.000193\n",
              "22276           percentage_.  12.484425  0.000418\n",
              "8205                     all  12.408623  0.000435\n",
              "15678              generally  12.312552  0.000458\n",
              "12907                 differ  11.297795  0.000788\n",
              "19164                 listen  11.160429  0.000848\n",
              "19824    mean_per_sentence_.  10.903873  0.000973\n",
              "23272                program  10.807250  0.001025\n",
              "30213                  write  10.618366  0.001135\n",
              "23770                  ready  10.469372  0.001230\n",
              "27994               together  10.387944  0.001285\n",
              "22314         percentage_PRP  10.384496  0.001287\n",
              "19829   mean_per_sentence_CC  10.258421  0.001378\n",
              "7813            acquaintance  10.180225  0.001437"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cNEU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>pvalue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21083</th>\n",
              "      <td>not</td>\n",
              "      <td>22.697085</td>\n",
              "      <td>0.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9410</th>\n",
              "      <td>beat</td>\n",
              "      <td>21.763796</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19832</th>\n",
              "      <td>mean_per_sentence_DT</td>\n",
              "      <td>20.418290</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24873</th>\n",
              "      <td>scared</td>\n",
              "      <td>20.393448</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17127</th>\n",
              "      <td>hurt</td>\n",
              "      <td>18.216863</td>\n",
              "      <td>0.000020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28899</th>\n",
              "      <td>unnormalized_VBP</td>\n",
              "      <td>17.856530</td>\n",
              "      <td>0.000025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14340</th>\n",
              "      <td>everything</td>\n",
              "      <td>16.608041</td>\n",
              "      <td>0.000047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22284</th>\n",
              "      <td>percentage_DT</td>\n",
              "      <td>16.477806</td>\n",
              "      <td>0.000051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16449</th>\n",
              "      <td>hate</td>\n",
              "      <td>16.157224</td>\n",
              "      <td>0.000060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29505</th>\n",
              "      <td>want</td>\n",
              "      <td>16.107376</td>\n",
              "      <td>0.000062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28884</th>\n",
              "      <td>unnormalized_PRP</td>\n",
              "      <td>15.938537</td>\n",
              "      <td>0.000067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29974</th>\n",
              "      <td>wish</td>\n",
              "      <td>15.749190</td>\n",
              "      <td>0.000074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22314</th>\n",
              "      <td>percentage_PRP</td>\n",
              "      <td>15.306689</td>\n",
              "      <td>0.000094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14817</th>\n",
              "      <td>feel</td>\n",
              "      <td>15.154502</td>\n",
              "      <td>0.000102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>-PRON-</td>\n",
              "      <td>15.119014</td>\n",
              "      <td>0.000104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19830</th>\n",
              "      <td>mean_per_sentence_CD</td>\n",
              "      <td>14.982719</td>\n",
              "      <td>0.000111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13216</th>\n",
              "      <td>do</td>\n",
              "      <td>14.637950</td>\n",
              "      <td>0.000134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26657</th>\n",
              "      <td>stressed</td>\n",
              "      <td>13.944997</td>\n",
              "      <td>0.000193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19870</th>\n",
              "      <td>mean_per_sentence_TIME</td>\n",
              "      <td>13.837068</td>\n",
              "      <td>0.000204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24872</th>\n",
              "      <td>scare</td>\n",
              "      <td>13.669691</td>\n",
              "      <td>0.000223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         name      score    pvalue\n",
              "21083                     not  22.697085  0.000002\n",
              "9410                     beat  21.763796  0.000003\n",
              "19832    mean_per_sentence_DT  20.418290  0.000007\n",
              "24873                  scared  20.393448  0.000007\n",
              "17127                    hurt  18.216863  0.000020\n",
              "28899        unnormalized_VBP  17.856530  0.000025\n",
              "14340              everything  16.608041  0.000047\n",
              "22284           percentage_DT  16.477806  0.000051\n",
              "16449                    hate  16.157224  0.000060\n",
              "29505                    want  16.107376  0.000062\n",
              "28884        unnormalized_PRP  15.938537  0.000067\n",
              "29974                    wish  15.749190  0.000074\n",
              "22314          percentage_PRP  15.306689  0.000094\n",
              "14817                    feel  15.154502  0.000102\n",
              "97                     -PRON-  15.119014  0.000104\n",
              "19830    mean_per_sentence_CD  14.982719  0.000111\n",
              "13216                      do  14.637950  0.000134\n",
              "26657                stressed  13.944997  0.000193\n",
              "19870  mean_per_sentence_TIME  13.837068  0.000204\n",
              "24872                   scare  13.669691  0.000223"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cAGR\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>pvalue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14700</th>\n",
              "      <td>family</td>\n",
              "      <td>17.925416</td>\n",
              "      <td>0.000024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26755</th>\n",
              "      <td>stupid</td>\n",
              "      <td>15.150077</td>\n",
              "      <td>0.000102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30140</th>\n",
              "      <td>worried</td>\n",
              "      <td>14.654190</td>\n",
              "      <td>0.000132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20997</th>\n",
              "      <td>no</td>\n",
              "      <td>13.635758</td>\n",
              "      <td>0.000227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21100</th>\n",
              "      <td>nothing</td>\n",
              "      <td>12.694646</td>\n",
              "      <td>0.000374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29559</th>\n",
              "      <td>waste</td>\n",
              "      <td>12.568196</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26843</th>\n",
              "      <td>suck</td>\n",
              "      <td>11.874212</td>\n",
              "      <td>0.000579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15483</th>\n",
              "      <td>fucking</td>\n",
              "      <td>11.789200</td>\n",
              "      <td>0.000606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15177</th>\n",
              "      <td>fool</td>\n",
              "      <td>11.416183</td>\n",
              "      <td>0.000739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15479</th>\n",
              "      <td>fuck</td>\n",
              "      <td>11.279560</td>\n",
              "      <td>0.000796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14359</th>\n",
              "      <td>evil</td>\n",
              "      <td>11.083279</td>\n",
              "      <td>0.000884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2134</th>\n",
              "      <td>Christian</td>\n",
              "      <td>11.064260</td>\n",
              "      <td>0.000893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19831</th>\n",
              "      <td>mean_per_sentence_DATE</td>\n",
              "      <td>11.058002</td>\n",
              "      <td>0.000896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25593</th>\n",
              "      <td>sister</td>\n",
              "      <td>11.034015</td>\n",
              "      <td>0.000908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15793</th>\n",
              "      <td>girlfriend</td>\n",
              "      <td>10.773523</td>\n",
              "      <td>0.001044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9115</th>\n",
              "      <td>awesome</td>\n",
              "      <td>10.742732</td>\n",
              "      <td>0.001061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25363</th>\n",
              "      <td>shit</td>\n",
              "      <td>10.473584</td>\n",
              "      <td>0.001227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19587</th>\n",
              "      <td>manager</td>\n",
              "      <td>10.434663</td>\n",
              "      <td>0.001253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10639</th>\n",
              "      <td>catch</td>\n",
              "      <td>9.952804</td>\n",
              "      <td>0.001625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18930</th>\n",
              "      <td>learning</td>\n",
              "      <td>9.893998</td>\n",
              "      <td>0.001678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         name      score    pvalue\n",
              "14700                  family  17.925416  0.000024\n",
              "26755                  stupid  15.150077  0.000102\n",
              "30140                 worried  14.654190  0.000132\n",
              "20997                      no  13.635758  0.000227\n",
              "21100                 nothing  12.694646  0.000374\n",
              "29559                   waste  12.568196  0.000400\n",
              "26843                    suck  11.874212  0.000579\n",
              "15483                 fucking  11.789200  0.000606\n",
              "15177                    fool  11.416183  0.000739\n",
              "15479                    fuck  11.279560  0.000796\n",
              "14359                    evil  11.083279  0.000884\n",
              "2134                Christian  11.064260  0.000893\n",
              "19831  mean_per_sentence_DATE  11.058002  0.000896\n",
              "25593                  sister  11.034015  0.000908\n",
              "15793              girlfriend  10.773523  0.001044\n",
              "9115                  awesome  10.742732  0.001061\n",
              "25363                    shit  10.473584  0.001227\n",
              "19587                 manager  10.434663  0.001253\n",
              "10639                   catch   9.952804  0.001625\n",
              "18930                learning   9.893998  0.001678"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cCON\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>pvalue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28853</th>\n",
              "      <td>unnormalized_DATE</td>\n",
              "      <td>30.151966</td>\n",
              "      <td>4.403754e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19831</th>\n",
              "      <td>mean_per_sentence_DATE</td>\n",
              "      <td>24.369890</td>\n",
              "      <td>8.481386e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22283</th>\n",
              "      <td>percentage_DATE</td>\n",
              "      <td>23.691959</td>\n",
              "      <td>1.201977e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29638</th>\n",
              "      <td>week</td>\n",
              "      <td>17.971624</td>\n",
              "      <td>2.324790e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26721</th>\n",
              "      <td>student</td>\n",
              "      <td>17.334195</td>\n",
              "      <td>3.242611e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28047</th>\n",
              "      <td>tonight</td>\n",
              "      <td>16.271930</td>\n",
              "      <td>5.653954e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7650</th>\n",
              "      <td>able</td>\n",
              "      <td>15.837040</td>\n",
              "      <td>7.103108e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27975</th>\n",
              "      <td>today</td>\n",
              "      <td>15.001619</td>\n",
              "      <td>1.102155e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10767</th>\n",
              "      <td>chance</td>\n",
              "      <td>14.144622</td>\n",
              "      <td>1.732208e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22323</th>\n",
              "      <td>percentage_TO</td>\n",
              "      <td>13.709888</td>\n",
              "      <td>2.180088e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19871</th>\n",
              "      <td>mean_per_sentence_TO</td>\n",
              "      <td>13.407705</td>\n",
              "      <td>2.558638e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29358</th>\n",
              "      <td>vocabulary</td>\n",
              "      <td>12.332930</td>\n",
              "      <td>4.530346e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28893</th>\n",
              "      <td>unnormalized_TO</td>\n",
              "      <td>12.312994</td>\n",
              "      <td>4.578743e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27951</th>\n",
              "      <td>to</td>\n",
              "      <td>12.104118</td>\n",
              "      <td>5.118341e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16124</th>\n",
              "      <td>group</td>\n",
              "      <td>11.863903</td>\n",
              "      <td>5.818878e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15338</th>\n",
              "      <td>freaky</td>\n",
              "      <td>11.802551</td>\n",
              "      <td>6.012840e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18563</th>\n",
              "      <td>keyboard</td>\n",
              "      <td>11.276580</td>\n",
              "      <td>7.968378e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15724</th>\n",
              "      <td>get</td>\n",
              "      <td>11.142872</td>\n",
              "      <td>8.560887e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22291</th>\n",
              "      <td>percentage_IN</td>\n",
              "      <td>11.047086</td>\n",
              "      <td>9.012574e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>?</td>\n",
              "      <td>11.044627</td>\n",
              "      <td>9.024484e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         name      score        pvalue\n",
              "28853       unnormalized_DATE  30.151966  4.403754e-08\n",
              "19831  mean_per_sentence_DATE  24.369890  8.481386e-07\n",
              "22283         percentage_DATE  23.691959  1.201977e-06\n",
              "29638                    week  17.971624  2.324790e-05\n",
              "26721                 student  17.334195  3.242611e-05\n",
              "28047                 tonight  16.271930  5.653954e-05\n",
              "7650                     able  15.837040  7.103108e-05\n",
              "27975                   today  15.001619  1.102155e-04\n",
              "10767                  chance  14.144622  1.732208e-04\n",
              "22323           percentage_TO  13.709888  2.180088e-04\n",
              "19871    mean_per_sentence_TO  13.407705  2.558638e-04\n",
              "29358              vocabulary  12.332930  4.530346e-04\n",
              "28893         unnormalized_TO  12.312994  4.578743e-04\n",
              "27951                      to  12.104118  5.118341e-04\n",
              "16124                   group  11.863903  5.818878e-04\n",
              "15338                  freaky  11.802551  6.012840e-04\n",
              "18563                keyboard  11.276580  7.968378e-04\n",
              "15724                     get  11.142872  8.560887e-04\n",
              "22291           percentage_IN  11.047086  9.012574e-04\n",
              "937                         ?  11.044627  9.024484e-04"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cOPN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>pvalue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19831</th>\n",
              "      <td>mean_per_sentence_DATE</td>\n",
              "      <td>45.286764</td>\n",
              "      <td>2.109144e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15854</th>\n",
              "      <td>go</td>\n",
              "      <td>40.850357</td>\n",
              "      <td>1.958773e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22323</th>\n",
              "      <td>percentage_TO</td>\n",
              "      <td>39.779853</td>\n",
              "      <td>3.358289e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28853</th>\n",
              "      <td>unnormalized_DATE</td>\n",
              "      <td>38.105557</td>\n",
              "      <td>7.812635e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16834</th>\n",
              "      <td>home</td>\n",
              "      <td>35.550844</td>\n",
              "      <td>2.841205e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11053</th>\n",
              "      <td>class</td>\n",
              "      <td>35.023902</td>\n",
              "      <td>3.709766e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16862</th>\n",
              "      <td>homework</td>\n",
              "      <td>30.515209</td>\n",
              "      <td>3.660027e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22311</th>\n",
              "      <td>percentage_PERSON</td>\n",
              "      <td>30.161947</td>\n",
              "      <td>4.381422e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12091</th>\n",
              "      <td>create</td>\n",
              "      <td>28.816479</td>\n",
              "      <td>8.700379e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22274</th>\n",
              "      <td>percentage_-LRB-</td>\n",
              "      <td>28.168880</td>\n",
              "      <td>1.210981e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28844</th>\n",
              "      <td>unnormalized_-LRB-</td>\n",
              "      <td>27.876258</td>\n",
              "      <td>1.406270e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19871</th>\n",
              "      <td>mean_per_sentence_TO</td>\n",
              "      <td>27.841998</td>\n",
              "      <td>1.431109e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19822</th>\n",
              "      <td>mean_per_sentence_-LRB-</td>\n",
              "      <td>27.608424</td>\n",
              "      <td>1.612592e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>(</td>\n",
              "      <td>27.306209</td>\n",
              "      <td>1.882096e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24919</th>\n",
              "      <td>school</td>\n",
              "      <td>26.881548</td>\n",
              "      <td>2.338868e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22284</th>\n",
              "      <td>percentage_DT</td>\n",
              "      <td>24.619151</td>\n",
              "      <td>7.461680e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21310</th>\n",
              "      <td>of</td>\n",
              "      <td>24.302499</td>\n",
              "      <td>8.780342e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>)</td>\n",
              "      <td>24.248664</td>\n",
              "      <td>9.026741e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28845</th>\n",
              "      <td>unnormalized_-RRB-</td>\n",
              "      <td>23.749731</td>\n",
              "      <td>1.166767e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19823</th>\n",
              "      <td>mean_per_sentence_-RRB-</td>\n",
              "      <td>23.703810</td>\n",
              "      <td>1.194668e-06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          name      score        pvalue\n",
              "19831   mean_per_sentence_DATE  45.286764  2.109144e-11\n",
              "15854                       go  40.850357  1.958773e-10\n",
              "22323            percentage_TO  39.779853  3.358289e-10\n",
              "28853        unnormalized_DATE  38.105557  7.812635e-10\n",
              "16834                     home  35.550844  2.841205e-09\n",
              "11053                    class  35.023902  3.709766e-09\n",
              "16862                 homework  30.515209  3.660027e-08\n",
              "22311        percentage_PERSON  30.161947  4.381422e-08\n",
              "12091                   create  28.816479  8.700379e-08\n",
              "22274         percentage_-LRB-  28.168880  1.210981e-07\n",
              "28844       unnormalized_-LRB-  27.876258  1.406270e-07\n",
              "19871     mean_per_sentence_TO  27.841998  1.431109e-07\n",
              "19822  mean_per_sentence_-LRB-  27.608424  1.612592e-07\n",
              "53                           (  27.306209  1.882096e-07\n",
              "24919                   school  26.881548  2.338868e-07\n",
              "22284            percentage_DT  24.619151  7.461680e-07\n",
              "21310                       of  24.302499  8.780342e-07\n",
              "55                           )  24.248664  9.026741e-07\n",
              "28845       unnormalized_-RRB-  23.749731  1.166767e-06\n",
              "19823  mean_per_sentence_-RRB-  23.703810  1.194668e-06"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "# Accuracy and F1 scores for best features\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>acc</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cEXT</td>\n",
              "      <td>0.515397</td>\n",
              "      <td>0.678149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cNEU</td>\n",
              "      <td>0.508914</td>\n",
              "      <td>0.183288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cAGR</td>\n",
              "      <td>0.534846</td>\n",
              "      <td>0.690399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cCON</td>\n",
              "      <td>0.513776</td>\n",
              "      <td>0.630542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cOPN</td>\n",
              "      <td>0.520259</td>\n",
              "      <td>0.680346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  feature       acc        f1\n",
              "0    cEXT  0.515397  0.678149\n",
              "1    cNEU  0.508914  0.183288\n",
              "2    cAGR  0.534846  0.690399\n",
              "3    cCON  0.513776  0.630542\n",
              "4    cOPN  0.520259  0.680346"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}